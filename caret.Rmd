---
title: "Machine Learning with R and Caret"
author: "Carlos Fernandez-Lozano, PhD"
date: '`r format(Sys.Date(),"Last modified: %e %b %Y")`'
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

__DISCLAIMER__ this course is for teaching purposes, not for a regular cancer analysis using ML.

# Session info

`sessionInfo()` display which version of R you are running in which platform and operative system, the locale you are using and the attached packages.

```{r echo=FALSE}
setwd(dir = '/home/cfernandez/git/es_fic_mubics_caret/')
```


```{r}
library(TCGAbiolinks)
library(SummarizedExperiment)
library(biomaRt)
library(GEOquery)
library(ggplot2)
library(caret)
library(tibble)
library(tidyr)
library(dplyr)
library(stringr)
sessionInfo()
```


# Outline

In this course, we review some of the fundamentals of machine learning (ML) with `Caret` and R. Topics covered include: 

* Exploratory data analysis
* Data pre-processing
* Filter feature selection
* Machine learning models: Random Forest and Naive Bayes
* Model comparison

And the question now is the following: What is Machine Learning? Firstly, a hot topic in the last years. Generally speaking, a system that can access data and use it to learn and extract underlying knowledge from it in order to automatically learn without being explicitly programmed for it. So, it learns from your data (handle with care), it's fast and it tends to overfits to your data (handle with care). So we are able to build a model on the data and then use it to predict on new data. They learn patterns from the data so a particular pattern not present in your data could not been predicted nor even known by the model. Furthermore, the big assumption here is that "what we learn from the past will be used to predict the future" and as we know, the future in unpredictable. So **handle with care** following a good experimental design to reduce the uncertainties.

A ML is said to overfit if the algoritms is more accurate predicting/fitting to known data (used in the training of the algorithm) than in predicting with new unknown data. A good generalization capability is thus desired. We will cover some tasks for a proper experimental design in classification problems despite the fact that there are other problems in ML research such as: regression, survival, clustering and much more. A methodology for the design of experiments with regression models is available open access [here](https://peerj.com/articles/2721/).

# Caret

Nowadays one of the strenghts in ML research is that you can search for a particular algorithm in a particular programming language and you'll have several different implemenations. Even more, if you need to build a ML model you'll have several differnt robust methodologies. At the same time, the big drawback is that everything is here and YOU must handle it with care. Otherways you'll build a bad model with a poor prediction and generalization capability. This means **problems**!

One of the biggest efforts to normalize, democratize and standardize ML using R is the `Caret` package, a bookdown [here](https://topepo.github.io/caret/). Developed by Max Kuhn, is a single interface to hundred or thousands of functions through a complex ML pipeline. The `caret` package (short for **C**lassification **A**nd **R**egression **T**raining) contains tools for:

* data splitting
* pre-processing
* feature selection
* model tuning
* variable importance
* and much more functionalities...

Following the `caret` documentation [suggestion](https://cran.r-project.org/web/packages/caret/vignettes/caret.html), in order to install the package execute the following package to ensure that all needed packages are installed and resolve all the dependencies:

```{r eval=FALSE}
install.packages("caret", dependencies = c("Depends", "Suggests"))
```
Be patient, it may take a while!

# Session info

```{r}
sessionInfo()
```


# TCGA - BRCA dataset

Following the same steps that we used in the previous [course](https://cafernandezlo.github.io/es_fic_mubics_ggplot_dplyr/ggplot-dplyr.html) we will download the TCGA-BRCA and in particular: transcriptome profiling of gene expression quantification where the experimental strategy is (RNAseq) and the workflow type is HTSeq-FPKM-UQ and only primary solid tumor data of the affymetrix GPL86 profile.

```{r eval=FALSE}
query = GDCquery(project = 'TCGA-BRCA', 
         data.category = 'Transcriptome Profiling',
         data.type = 'Gene Expression Quantification',
         experimental.strategy = 'RNA-Seq',
         workflow.type = 'HTSeq - FPKM-UQ')

GDCdownload(query)

brca.expDat = GDCprepare(query = query,
                    save = T,
                    save.filename = "TCGA-BRCA-RNASeq",
                    remove.files.prepared =  TRUE)

brca.omics = assay(brca.expDat)
brca.omics = as.data.frame(t(brca.omics))

samples = colData(brca.expDat)
rownames(samples) = 1:nrow(samples)
ptSamples = samples[which(samples$definition == 'Primary solid Tumor'), ]

ptSamples = ptSamples[, c('barcode', 'patient', 'vital_status', 'days_to_last_follow_up', 'days_to_death', 'gender', 'age_at_diagnosis','ajcc_pathologic_stage',
                          'tumor_stage','ajcc_pathologic_n','tumor_grade')]

mart <- useDataset("hsapiens_gene_ensembl", useMart("ensembl"))
convert <- getBM(filters= c('ensembl_gene_id'), 
                 attributes= c('ensembl_gene_id', 'gene_biotype'),
                 values=names(brca.omics),
                 mart= mart)
protCod = convert[which(convert$gene_biotype == 'protein_coding'), ]
protCodIDs = protCod$ensembl_gene_id
brca.omics = brca.omics[, match(protCodIDs, names(brca.omics))]

platID96 = 'GPL96'

gpl96 = getGEO(platID96)

gpl96 = gpl96@dataTable@table
annot96 = gpl96[, c('ID', 'Gene Symbol', 'Gene Title', 'ENTREZ_GENE_ID')]

dict96 = getBM(filters= c('affy_hg_u133a'), 
               attributes= c('ensembl_gene_id', 'affy_hg_u133a','hgnc_symbol'),
               values= annot96$ID,
               mart= mart)

genes96 = unique(dict96$ensembl_gene_id)
brca.omics.96 = brca.omics[, intersect(names(brca.omics), genes96)]

colnames(brca.omics.96)<- dict96$hgnc_symbol[match(colnames(brca.omics.96),dict96$ensembl_gene_id)]
```

__NOTE:__ Files `brca.omics.96` and `ptSamples` are available for download from the Universidade da CoruÃ±a's community in Zenodo [here](https://doi.org/10.5281/zenodo.4309168). Load them in R using the `readRDS()` function.

```{r}
brca.omics.96<-readRDS(file = '~/Downloads/TCGA.BRCA.brca.omics.96.RData')
ptSamples <- readRDS(file = '~/Downloads/TCGA.BRCA.ptSamples.RData')
```


## Exploratory data analysis

Before training any ML model it's important to understand your data. Thus, an initial descriptive exploratory analysis is of interest. For exaple, some typical errors arise during the loading process of the data. Furthermore, sometimes codification problems such as slash, values of 0 for unknown data or other similar situations.

## Features types.

One of the initial steps should be the check of the types of the features in order to check that all numeric values are numbers for R and that cualitative features are factor or boolean for example. You can do this task with `str()` from base or `glimpse` from `Tibble` for example:

```{r}
str(brca.omics.96)
```

```{r}
glimpse(brca.omics.96)
```

We lost some information in the previous matching process using `BioMart` and we also observed that some of the genes have 0's.

```{r}
str(ptSamples)
ptSamples<-as.data.frame(ptSamples)
```

We have all the cuantitative features as `character` so we should fix this. In this case, we will add new features with an extension in order to have a copy of the original feature for reproducibility and error checking pouposes.

```{r}
ptSamples$gender.fac <- as.factor(ptSamples$gender)
ptSamples$vital_status.fac <- as.factor(ptSamples$vital_status)
```

In case of further changes we'll fix features in the following part of the course.

We have to remove firstly those features without a gene name (empty colnames) because `dplyr` cannot deal with repeated colnames.

```{r}
brca.omics.96 <-subset(brca.omics.96, select=which(!duplicated(names(brca.omics.96)))) 
keep.cols <- names(brca.omics.96) %in% c("")
brca.omics.96 <- brca.omics.96 [!keep.cols] 
```

We should check for NA's in both files:

```{r}
length(which(is.na(ptSamples)))
length(which(is.na(brca.omics.96)))
```

No NAs on omic data but in clinical.

We'll follow the `Tidiverse` philosophy in order to create a new data structure to facilitate further data visualizations.

```{r warning=FALSE}
ptSamples.tidy <- ptSamples %>% gather(key = "feature", value = "value", -barcode)
```

Let's ggplot the % of NAs in each of the clinical features.

```{r}
ptSamples.tidy %>%
  group_by(feature) %>% 
  summarize(NAs = 100 * sum(is.na(value)) / length(value)) %>%
  ggplot(aes(x = reorder(feature, dplyr::desc(NAs)), y = NAs)) +
    geom_col() +
    labs(title = "% of NA in clinical data", x=element_blank(), y = "% of NAs") +
    theme(axis.text.x = element_text(angle = 45,hjust = 1))
```

Summarising, we don't have enough data in `days_to_death` with a % of NAs higher than 86% and have some missing data in other features but seems to be afordable.

Let's check the distribution of `gender` and `vital_status`:

```{r}
ggplot(data = ptSamples, aes(x = gender.fac, y = ..count.., fill = gender.fac)) +
  geom_bar() +
  labs(fill='Gender',
       x=element_blank())
```

```{r}
ggplot(data = ptSamples, aes(x = vital_status.fac, y = ..count.., fill = vital_status.fac)) +
  geom_bar() +
  labs(fill='Vital status',
       x=element_blank())
```

In both cases, patient with barcode `TCGA-BH-A0B2-01A-11R-A10J-07` has all clinical values to NAs. We remove this patient.

```{r}
ptSamples<-ptSamples %>% filter(barcode!='TCGA-BH-A0B2-01A-11R-A10J-07')

ggplot(data = ptSamples, aes(x = vital_status.fac, y = ..count.., fill = vital_status.fac)) +
  geom_bar() +
  labs(fill='Vital status',
       x=element_blank())
```

Let's play with `ajcc_pathologic_stage` and remove blank spaces in the different stages with `stringr`:

```{r}
ptSamples$ajcc_pathologic_stage<-str_replace_all(ptSamples$ajcc_pathologic_stage, ' ','')
ptSamples$ajcc_pathologic_stage.fac <- as.factor(ptSamples$ajcc_pathologic_stage)
```


```{r}
ggplot(data = ptSamples, aes(x = ajcc_pathologic_stage.fac, y = ..count.., fill = ajcc_pathologic_stage.fac)) +
  geom_bar() +
  labs(fill='Stage',
       x=element_blank())+
  theme(axis.text.x = element_text(angle = 45,hjust = 1))
```

```{r}
ptSamples<-mutate(ptSamples, ajcc_pathologic_stage_new_3 =
         ifelse(ajcc_pathologic_stage %in% c('StageI','StageIA','StageIB'),'Stage1',
                ifelse(ajcc_pathologic_stage %in% c('StageII','StageIIA','StageIIB'),'Stage2',
                       ifelse(ajcc_pathologic_stage %in% c('StageIII','StageIIIA','StageIIIB','StageIIIC'),'Stage3',
                              ifelse(ajcc_pathologic_stage %in% c('StageIV','StageX'),'Stage4','Others')
                                )
                       )
                )
       )

ggplot(data = ptSamples, aes(x = ajcc_pathologic_stage_new_3, y = ..count.., fill = ajcc_pathologic_stage_new_3)) +
  geom_bar() +
  labs(fill='New stage with 3 levels',
       x=element_blank(),
       y=element_blank())+
  theme(axis.text.x = element_text(angle = 45,hjust = 1))
```


```{r warning=FALSE}
ptSamples<-mutate(ptSamples, age_at_diagnosis.fac =
         ifelse(age_at_diagnosis<21560,'early','late')
       )

ggplot(data = ptSamples, aes(x = age_at_diagnosis.fac, y = ..count.., fill = age_at_diagnosis.fac)) +
  geom_bar() +
  labs(fill='Age at diagnosis',
       x=element_blank(),
       y=element_blank())+
  theme(axis.text.x = element_text(angle = 45,hjust = 1))
```

We will study if there exist a genomic pattern for classifying BRCA patients according with this new binary age at diagnosis.

```{r}
ptSamples<-ptSamples %>% drop_na(age_at_diagnosis.fac)
```

## Train and test dataset

In order to evaluate the predictive power of the ML we must ensure that the model's performance should be equal (or close to) with unknown new patients. In orther to do this, we'll separate the dataset in two groups: training and test (80-20%) according with the output. Furthermore, this dataset has a FPKM normalization (reads/fragments per kilobase of exon per million reads/fragments mapped) but most of the ML models are sensible to differences in the scale of the features so, there are mainly two different approaches: normalization or standardization. Generally speaking, standardization (scale the features to have a mean of 0 and a standard deviation of 1) is preferred. In R we have the `scale()` function. This step belongs to the next section (data preprocessing) but it's preferable to do it before data splitting. 

```{r}
brca.data <- as.data.frame(scale(brca.omics.96))
mean(brca.data$TP53)
sd(brca.data$TP53)

brca.data$output <- ptSamples[match(row.names(brca.data),ptSamples$barcode),"age_at_diagnosis.fac"]
brca.data <- brca.data %>% drop_na(output)
```

Ok but, what does this standardization looks like? in order to use `ggplot2` to boxplot three aleatory genes we need data in [long format](https://statisticsglobe.com/reshape-data-frame-from-wide-to-long-format-in-r) and fortunatelly we have the `reshape` package and the `melt()` function to help us.

```{r warning=FALSE}
library(reshape2)
data.raw <- melt(brca.omics.96[,c(1,2,3)])
data.scale <- melt(brca.data[,c(1,2,3)])
```

```{r}
ggplot(data.raw, aes(x = variable, y = value, fill=variable)) +
  geom_boxplot()+
  labs(x=element_blank(),
       y=element_blank(),
       fill='Genes (raw)')
```

```{r}
ggplot(data.scale, aes(x = variable, y = value, fill=variable)) +
  geom_boxplot()+
  labs(x=element_blank(),
       y=element_blank(),
       fill='Genes (standardized)')
```

Looks pretty similar, or not? Let's check what's going on:

```{r}
data.raw$type <- 'raw'
data.scale$type <- 'standardized'
data.comparison <- rbind(data.raw,data.scale)
ggplot(data.comparison, aes(x = variable, y = value, fill=type)) +
  geom_boxplot()+
  labs(x=element_blank(),
       y=element_blank(),
       fill='Scales')
```

A good idea is to stratify the groups to have equal proportion of each one of the classes (in binary classification).

```{r}
set.seed(23)

train <- createDataPartition(y = brca.data$output, p = 0.8, list = FALSE, times = 1)
brca.data_train <- brca.data[train, ]
brca.data_test  <- brca.data[-train, ]
```

## Data preprocessing

`Caret` has several different useful functions for all the steps of a ML analysis pipeline. One of them is `nearZeroVar()` to remove those features with a single value (zero-variance) because they are useless.

```{r}
nzv <- nearZeroVar(brca.data)
head(nzv)
length(nzv)
brca.data.nzv <- brca.data[,-nzv]
```

By default, `nearZeroVar` will return the positions of the problematic features. We remove those features.

Most of the models may benefit from reducing the level of correlation between features. More correlation does not imply more information and, on the other hand, likely imply more noise. `Caret` has a `findCorrelation()` function for this task.

```{r}
output <- brca.data.nzv %>% select('output')
data <- brca.data.nzv[,setdiff(colnames(brca.data.nzv),'output')]
high.cor <- findCorrelation(data, cutoff = .75)
brca.data.nzv.cor <- brca.data.nzv[,-high.cor]
brca.data.nzv.cor$output <- output
```

A cutoff of `.75` is clearly too much ;)

We will keep the final set of genes as the ones of interest so we must keep them too in the train and test datasets:

```{r}
brca.data_train <- brca.data_train %>% select(names(brca.data.nzv.cor))
brca.data_test <- brca.data_test %>% select(names(brca.data.nzv.cor))
```


# Summary

In this course we have covered the following concepts:

* Bla bla
